import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import scipy.io
from scipy.signal import spectrogram

# å‚æ•°è®¾ç½® - ä¸maxed2.pyä¿æŒä¸€è‡´
Fs = 2000
window_size = 200
overlap = 100        # å¸§ç§»=200-100=100ä¸ªç‚¹=0.05ç§’
nfft = 200

def process_emg_data(mat_file: str, var_name: str) -> np.ndarray:
    """
    æ•°æ®é¢„å¤„ç†å‡½æ•°ï¼Œä¸maxed2.pyå®Œå…¨ä¸€è‡´çš„å¤„ç†æ–¹å¼
    """
    print(f"\nå¤„ç†æ•°æ®é›†: {mat_file} - {var_name}")
    mat_data = scipy.io.loadmat(mat_file)
    data_matrix = mat_data[var_name]
    labels = data_matrix[:, 0].astype(int)
    raw = data_matrix[:, 1:]
    
    # æŒ‰æ ‡ç­¾åˆ†ç»„æ•´ç†æ•°æ®
    channel_data = {}
    for lab, row in zip(labels, raw):
        channel_data.setdefault(lab, []).append(row)
    for ch in channel_data:
        channel_data[ch] = np.stack(channel_data[ch], axis=0)
    
    num_samples = channel_data[0].shape[0]
    print(f"åŸå§‹æ ·æœ¬æ•°: {num_samples}")
    
    # === æ–°å¢ï¼šå°†3ä¸ªæ ·æœ¬æ‹¼æ¥æˆ1ä¸ªæ ·æœ¬ ===
    if num_samples >= 3:
        # æ¯3ä¸ªæ ·æœ¬ä¸ºä¸€ç»„è¿›è¡Œæ‹¼æ¥
        n_groups = num_samples // 3
        print(f"å°† {num_samples} ä¸ªæ ·æœ¬æ‹¼æ¥æˆ {n_groups} ä¸ªé•¿æ ·æœ¬")
        
        # ä¸ºæ¯ä¸ªé€šé“åˆ›å»ºæ‹¼æ¥åçš„æ•°æ®
        concatenated_channel_data = {}
        for ch in range(4):
            concatenated_samples = []
            for group_idx in range(n_groups):
                start_idx = group_idx * 3
                end_idx = start_idx + 3
                # å–3ä¸ªæ ·æœ¬å¹¶åœ¨æ—¶é—´ç»´åº¦æ‹¼æ¥
                group_samples = channel_data[ch][start_idx:end_idx]  # (3, signal_length)
                concat_sample = np.concatenate(group_samples, axis=0)  # (3*signal_length,)
                concatenated_samples.append(concat_sample)
            concatenated_channel_data[ch] = np.stack(concatenated_samples, axis=0)
        
        # æ›´æ–°é€šé“æ•°æ®å’Œæ ·æœ¬æ•°
        channel_data = concatenated_channel_data
        num_samples = n_groups
        
        print(f"æ‹¼æ¥åæ ·æœ¬æ•°: {num_samples}")
        print(f"æ¯ä¸ªæ ·æœ¬é•¿åº¦: {channel_data[0].shape[1]}")
    
    # è®¡ç®—æ–°çš„æ—¶é—´å¸§æ•°
    signal_length = channel_data[0].shape[1]  # æ‹¼æ¥åçš„ä¿¡å·é•¿åº¦ = 18000
    frame_shift = window_size - overlap  # 100ä¸ªç‚¹
    estimated_frames = (signal_length - window_size) // frame_shift + 1
    print(f"é¢„ä¼°æ—¶é—´å¸§æ•°: {estimated_frames}")
    print(f"æ¯å¸§æ—¶é—´: {frame_shift / Fs:.3f}ç§’")
    
    # ç”Ÿæˆé¢‘è°±å›¾
    spectrogram_list = []
    for i in range(num_samples):
        sample = np.zeros((4, channel_data[0].shape[1]))  # ä½¿ç”¨æ‹¼æ¥åçš„é•¿åº¦
        for ch in range(4):
            sample[ch] = channel_data[ch][i]
        
        # åŠ¨æ€åˆ†é…è°±å›¾çŸ©é˜µå¤§å°
        spec_mat = np.zeros((estimated_frames, 4, 20))
        
        for ch in range(4):
            f, t, Sxx = spectrogram(
                sample[ch], fs=Fs, window='hamming',
                nperseg=window_size, noverlap=overlap, nfft=nfft
            )
            idx = np.where((f>=10)&(f<=200))[0]
            Ssel = Sxx[idx, :]
            
            # è°ƒæ•´åˆ°é¢„ä¼°å¸§æ•°
            actual_frames = Ssel.shape[1]
            if actual_frames > estimated_frames:
                Ssel = Ssel[:, :estimated_frames]  # æˆªæ–­
            elif actual_frames < estimated_frames:
                # è¡¥é›¶
                padding = np.zeros((20, estimated_frames - actual_frames))
                Ssel = np.concatenate([Ssel, padding], axis=1)
            
            spec_mat[:, ch, :] = Ssel.T
        
        spectrogram_list.append(spec_mat)
    
    print(f"ç”Ÿæˆ {len(spectrogram_list)} ä¸ªè°±å›¾çŸ©é˜µï¼Œæ¯ä¸ªå½¢çŠ¶ä¸º {spec_mat.shape}")
    
    # è½¬æ¢ä¸ºPyTorchæ ¼å¼: (n_samples, frames, 4, 20)
    spectrogram_array = np.stack(spectrogram_list, axis=0)
    
    return spectrogram_array.astype(np.float32)


class SpanningConv2D(nn.Module):
    """
    Spanning Convolution 2D layer for frequency domain sEMG processing
    Modified for 4-channel muscle configuration with fusion
    """

    def __init__(self, in_channels, out_channels, kernel_size, spanning_type='2x2',
                 stride=1, padding=0, bias=True):
        super(SpanningConv2D, self).__init__()

        self.spanning_type = spanning_type
        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)
        self.stride = stride
        self.padding = padding

        # Define spanning configurations for 4-muscle layout
        if spanning_type == '2x2':
            # 4è‚Œè‚‰åˆ†ç»„: å·¦ä¾§(0,1) vs å³ä¾§(2,3)
            self.muscle_pairs = [(0, 1), (2, 3)]
            self.num_muscle_groups = 2
            self.muscles_per_group = 2
        else:
            raise ValueError(f"Unsupported spanning_type: {spanning_type}")

        # ğŸ”§ å…³é”®ä¿®æ”¹ï¼šæ¯ä¸ªç»„è¾“å‡ºout_channels//2ï¼Œè¿™æ ·æ‹¼æ¥åæ­£å¥½æ˜¯out_channels
        channels_per_group = out_channels // self.num_muscle_groups
        
        # Create separate convolution layers for each muscle group
        self.conv_groups = nn.ModuleList()
        for _ in range(self.num_muscle_groups):
            self.conv_groups.append(
                nn.Conv2d(in_channels, channels_per_group, kernel_size, 
                         stride=stride, padding=padding, bias=bias)
            )

    def forward(self, x):
        """
        Forward pass for spanning convolution with fusion
        x shape: (batch_size, channels, 4_muscles, 20_freq)
        """
        batch_size, channels, muscles, freq_bins = x.shape
        assert muscles == 4, f"Expected 4 muscle channels, got {muscles}"

        outputs = []

        if self.spanning_type == '2x2':
            # å·¦ä¾§è‚Œè‚‰ç¾¤: [0, 1]
            left_muscles = x[:, :, [0, 1], :]  # (batch_size, channels, 2, 20)
            left_output = self.conv_groups[0](left_muscles)  # (batch, out_channels//2, 1, 16)
            outputs.append(left_output)
            
            # å³ä¾§è‚Œè‚‰ç¾¤: [2, 3]
            right_muscles = x[:, :, [2, 3], :]  # (batch_size, channels, 2, 20)
            right_output = self.conv_groups[1](right_muscles)  # (batch, out_channels//2, 1, 16)
            outputs.append(right_output)

        # ğŸ”¥ èåˆï¼šåœ¨é€šé“ç»´åº¦æ‹¼æ¥ï¼Œè€Œä¸æ˜¯è‚Œè‚‰ç»´åº¦
        output = torch.cat(outputs, dim=1)  # (batch, out_channels, 1, 16)
        
        return output


class FrequencyFrameEncoder(nn.Module):
    """
    é¢‘åŸŸå¸§ç¼–ç å™¨ï¼Œå¤„ç†å•å¸§é¢‘è°±å›¾æ•°æ® (4, 20)
    """
    
    def __init__(self, spanning_type='2x2'):
        super(FrequencyFrameEncoder, self).__init__()
        
        # ç¬¬ä¸€å±‚: Spanning convolution - è¾“å‡º32é€šé“ï¼ˆèåˆåï¼‰
        self.spanning_conv1 = SpanningConv2D(
            in_channels=1, out_channels=32,  # ç›´æ¥è¾“å‡º32é€šé“
            kernel_size=(2, 5), spanning_type=spanning_type,
            padding=(0, 0)
        )
        
        # æ± åŒ–å±‚
        self.pool1 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))
        
        # âœ… ç°åœ¨è¾“å…¥é€šé“æ•°æ­£ç¡®åŒ¹é…äº†
        self.conv2 = nn.Conv2d(32, 64, kernel_size=(1, 5), padding=(0, 0))
        
    def forward(self, x):
        """
        x shape: (batch_size, 4, 20) -> éœ€è¦æ·»åŠ channelç»´åº¦
        """
        # æ·»åŠ channelç»´åº¦: (batch_size, 4, 20) -> (batch_size, 1, 4, 20)
        if len(x.shape) == 3:
            x = x.unsqueeze(1)
        
        batch_size, channels, muscles, freq_bins = x.shape
        print(f"Frame input shape: {x.shape}")
        
        # ğŸ”¥ Spanning convolution with fusion: (batch, 1, 4, 20) -> (batch, 32, 1, 16)
        x = self.spanning_conv1(x)
        print(f"After spanning conv (fused): {x.shape}")
        x = F.relu(x)
        
        # Average pooling: (batch, 32, 1, 16) -> (batch, 32, 1, 8)
        x = self.pool1(x)
        print(f"After pool1: {x.shape}")
        
        # Second convolution: (batch, 32, 1, 8) -> (batch, 64, 1, 4)
        x = self.conv2(x)
        print(f"After conv2: {x.shape}")
        x = F.relu(x)
        
        # Flatten: (batch, 64, 1, 4) -> (batch, 256)
        x = x.view(x.size(0), -1)
        print(f"After flatten: {x.shape}")
        
        return x


class FrequencyDomainSCNN(nn.Module):
    """
    é¢‘åŸŸSCNNæ¨¡å‹ï¼Œç»“åˆTimeDistributed + LSTM
    """
    
    def __init__(self, spanning_type='2x2', lstm_hidden=256):
        super(FrequencyDomainSCNN, self).__init__()
        
        self.frame_encoder = FrequencyFrameEncoder(spanning_type=spanning_type)
        
        # âœ… LSTMè¾“å…¥ç»´åº¦æ¢å¤ä¸º256
        self.lstm = nn.LSTM(input_size=256, hidden_size=lstm_hidden, 
                           batch_first=True)
        
    def forward(self, x):
        """
        x shape: (batch_size, frames, 4, 20)
        """
        batch_size, frames, muscles, freq_bins = x.shape
        print(f"Input shape: {x.shape}")
        
        # å¤„ç†æ¯ä¸€å¸§
        frame_features = []
        for frame_idx in range(frames):
            frame_data = x[:, frame_idx, :, :]  # (batch, 4, 20)
            frame_feat = self.frame_encoder(frame_data)  # (batch, 256)
            frame_features.append(frame_feat)
        
        # å †å å¸§ç‰¹å¾: (batch, frames, 256)
        sequence_features = torch.stack(frame_features, dim=1)
        print(f"Sequence features shape: {sequence_features.shape}")
        
        # LSTMå¤„ç†æ—¶åºä¿¡æ¯
        lstm_out, (h_n, c_n) = self.lstm(sequence_features)
        
        # ä½¿ç”¨æœ€åçš„éšè—çŠ¶æ€ä½œä¸ºæœ€ç»ˆç‰¹å¾
        final_features = h_n[-1]  # (batch, lstm_hidden)
        print(f"Final features shape: {final_features.shape}")
        
        return final_features


def process_data_with_model(mat_path: str, var_name: str, model: FrequencyDomainSCNN, batch_size: int = 8) -> np.ndarray:
    """
    ä½¿ç”¨é¢‘åŸŸSCNNæ¨¡å‹å¤„ç†æ•°æ®å¹¶æå–ç‰¹å¾
    """
    spectrogram_data = process_emg_data(mat_path, var_name)
    print(f"åŠ è½½ {mat_path}ï¼Œè¾“å…¥å½¢çŠ¶: {spectrogram_data.shape}")
    
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    data_tensor = torch.tensor(spectrogram_data, dtype=torch.float32)
    
    model.eval()
    all_features = []
    
    # æ‰¹å¤„ç†æ¨ç†
    with torch.no_grad():
        for i in range(0, len(data_tensor), batch_size):
            batch = data_tensor[i:i+batch_size]
            features = model(batch)
            all_features.append(features.cpu().numpy())
    
    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç‰¹å¾
    all_features = np.concatenate(all_features, axis=0)
    print(f"æå–ç‰¹å¾: {all_features.shape}")
    return all_features


# Example usage and testing
if __name__ == "__main__":
    print("=== é¢‘åŸŸSCNN with LSTM Model Test ===")
    
    # è®¡ç®—æ‹¼æ¥åçš„æ—¶é—´å¸§æ•°
    estimated_frames = (18000 - window_size) // (window_size - overlap) + 1
    print(f"é¢„ä¼°æ—¶é—´å¸§æ•°: {estimated_frames}")
    print(f"æ¯å¸§æ—¶é—´: {(window_size - overlap) / Fs:.3f}ç§’")
    
    # æ•°æ®é›†åˆ—è¡¨
    datasets = [
        ('healthy_men_before.mat', 'combined_data'),
        ('healthy_men_after_add.mat', 'healthy_men_after')
    ]
    
    # åˆ›å»ºæ¨¡å‹
    model = FrequencyDomainSCNN(spanning_type='2x2', lstm_hidden=256)
    
    # æµ‹è¯•ç¬¬ä¸€ä¸ªæ•°æ®é›†
    first_path, first_var = datasets[0]
    test_data = process_emg_data(first_path, first_var)
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    # æµ‹è¯•æ¨¡å‹
    test_tensor = torch.tensor(test_data[:4], dtype=torch.float32)  # å–å‰4ä¸ªæ ·æœ¬æµ‹è¯•
    test_features = model(test_tensor)
    print(f"æµ‹è¯•è¾“å‡ºå½¢çŠ¶: {test_features.shape}")
    
    # æ‰“å°æ¨¡å‹å‚æ•°ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nModel Parameters:")
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    
    # å¤„ç†æ‰€æœ‰æ•°æ®é›†å¹¶ä¿å­˜ç‰¹å¾
    for mat_path, var_name in datasets:
        try:
            print(f"\nå¤„ç†æ–‡ä»¶: {mat_path}")
            features = process_data_with_model(mat_path, var_name, model, batch_size=4)
            
            # ä¿å­˜ç‰¹å¾åˆ° .npy æ–‡ä»¶
            out_name_npy = mat_path.replace('.mat', '_freq_scnn_features.npy')
            np.save(out_name_npy, features)
            print(f"ä¿å­˜ç‰¹å¾åˆ°: {out_name_npy}")
            print(f"ç‰¹å¾ç»´åº¦: {features.shape}")
            
        except Exception as e:
            print(f"å¤„ç† {mat_path} æ—¶å‡ºé”™: {e}")
    
    print("\n=== é¢‘åŸŸç‰¹å¾æå–å®Œæˆ ===")